{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    \"\"\"\n",
    "    Clean a line of text by strpping leading/training whitespace and specific unwanted characters.\n",
    "    \"\"\"\n",
    "    line = line.strip()\n",
    "    line = line.strip('\\u001b') # Remove BOM if present\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_faq(file_id):\n",
    "    \"\"\"\n",
    "    Reads a Google Docs exported as DOCX and extracts FAQ sections and questions.\n",
    "\n",
    "    Args:\n",
    "    file_id (str): The ID of the Google Docs document to be exported as DOCX.\n",
    "\n",
    "    Returns:\n",
    "    List[Dict]: A list of dictionaries, each containing a section, question, and answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the URL for downloading the DOCX file\n",
    "    url = f'https://docs.google.com/document/d/{file_id}/export?format=docx'\n",
    "\n",
    "    # Download the DOCX file\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status() # Raise an exception for HTTP errors\n",
    "\n",
    "    # Open the DOCX file\n",
    "    with io.BytesIO(response.content) as f_in:\n",
    "        doc = docx.Document(f_in)\n",
    "\n",
    "    # Initialize variables for storing the extracted data\n",
    "    questions = []\n",
    "    section_heading_style = 'heading 1'\n",
    "    question_heading_style = 'heading 2'\n",
    "\n",
    "    answer_text_so_far = ''\n",
    "    question_title = ''\n",
    "    section_title = ''\n",
    "\n",
    "    # Iterate through each paragraph in the document\n",
    "    for p in doc.paragraphs:\n",
    "        p_style = p.style.name.lower()\n",
    "        p_text = p.text\n",
    "\n",
    "        if len(p_text) == 0:\n",
    "            continue\n",
    "\n",
    "        if p_style == section_heading_style:\n",
    "            section_title = p_text    \n",
    "\n",
    "        if p_style == question_heading_style:\n",
    "            # if there is an ongoing answer, save it before starting a new question\n",
    "            answer_text_so_far = answer_text_so_far.strip()\n",
    "            if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "                questions.append({\n",
    "                    'section': section_title,\n",
    "                    'question': question_title,\n",
    "                    'text': answer_text_so_far\n",
    "                })\n",
    "                answer_text_so_far = ''\n",
    "\n",
    "            question_title = p_text\n",
    "            continue\n",
    "                \n",
    "        # Accumulate answer text\n",
    "        answer_text_so_far += '\\n' + p_text\n",
    "        \n",
    "    # Save the last accumulated answer\n",
    "    answer_text_so_far = answer_text_so_far.strip()\n",
    "    if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "        questions.append({\n",
    "            'section': section_title,\n",
    "            'question': question_title,\n",
    "            'text': answer_text_so_far\n",
    "        })\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_documents = {\n",
    "    'data-engineering-zoomcamp': '19bnYs80DwuUimHM65UV3sylsCn2j1vziPOwzBwQrebw',\n",
    "    'machine-learning-zoomcamp': '1LpPanc33QJJ6BSsyxVg-pWNMplal84TdZtq10naIhD8',\n",
    "    'mlops-zoomcamp': '12TlBfhIiKtyBv8RnsoJR6F72bkPDGEvPOItJIxaEzE0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-engineering-zoomcamp\n",
      "machine-learning-zoomcamp\n",
      "mlops-zoomcamp\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for course, file_id in faq_documents.items():\n",
    "    print(course)\n",
    "    course_documets = read_faq(file_id)\n",
    "    documents.append({'course': course, 'documents': course_documets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents.json', 'wt') as f_out:\n",
    "    json.dump(documents, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"documents\": [\n",
      "      {\n",
      "        \"section\": \"General course-related questions\",\n",
      "        \"question\": \"Course - When will the course start\\uff1f\",\n",
      "        \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nGeneral course-related questions\\nThe next cohort starts in Jan 2025. More info at DTC Article.\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\"\n",
      "      },\n",
      "      {\n"
     ]
    }
   ],
   "source": [
    "!head documents.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
